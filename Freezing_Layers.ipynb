{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Freezing_Layers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpd+00htuQURIObFe6WP9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solharsh/All_Neural_Networks/blob/master/Freezing_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ApFlISlzgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5a914bc2-7756-4b95-b2c7-760cf18a8aa7"
      },
      "source": [
        "pip install mxnet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n",
            "\u001b[K     |████████████████████████████████| 68.7MB 55kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m1aAi8vl64E",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning – Freezing layers\n",
        "\n",
        "After applying the pre-trained network’s weights, we usually freeze some layers in the network during training.\n",
        "\n",
        "We can also use the frozen part of the network as a feature extractor or Train another classifier using the output of the pre-trained network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKGyudgPl83o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d04b0880-d33b-4d18-e143-3156ccbe39b1"
      },
      "source": [
        "from mxnet.gluon.model_zoo import vision\n",
        "import mxnet as mx\n",
        " \n",
        "num_outputs = 5\n",
        " \n",
        "# change for cpu or gpu\n",
        "ctx = mx.cpu()\n",
        "#ctx = mx.gpu()\n",
        " \n",
        "# Let's get the pre-trained network and copy weights\n",
        "pre_trained_net = vision.alexnet(pretrained=True, ctx=ctx)\n",
        "net = vision.alexnet(classes=num_outputs, ctx=ctx)\n",
        "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
        "net.features = pre_trained_net.features"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/alexnet-44335d1f.zip646cac91-c25a-4c29-b824-5a10a2beda6e from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/alexnet-44335d1f.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtlBZvdHnMBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e4ba4b0d-0a99-4fa9-99f4-8470769db929"
      },
      "source": [
        "#The following code piece prints the weights for each layer.It also shows the layer name and its shape.\n",
        "\n",
        "for param in net.collect_params().values():\n",
        "    print(param)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter alexnet0_conv0_weight (shape=(64, 3, 11, 11), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv0_bias (shape=(64,), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv1_weight (shape=(192, 64, 5, 5), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv1_bias (shape=(192,), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv2_weight (shape=(384, 192, 3, 3), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv2_bias (shape=(384,), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv3_weight (shape=(256, 384, 3, 3), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv3_bias (shape=(256,), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv4_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_conv4_bias (shape=(256,), dtype=<class 'numpy.float32'>)\n",
            "Parameter alexnet0_dense0_weight (shape=(4096, 9216), dtype=float32)\n",
            "Parameter alexnet0_dense0_bias (shape=(4096,), dtype=float32)\n",
            "Parameter alexnet0_dense1_weight (shape=(4096, 4096), dtype=float32)\n",
            "Parameter alexnet0_dense1_bias (shape=(4096,), dtype=float32)\n",
            "Parameter alexnet1_dense2_weight (shape=(5, 0), dtype=float32)\n",
            "Parameter alexnet1_dense2_bias (shape=(5,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRVL9-p8nPUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's freeze all the layers until the flly connected layers (\"Dense layers\"). We can simply search for \"conv\" in the name of layer.\n",
        "\n",
        "# You can freeze some layers using the code below \n",
        "for param in net.collect_params().values(): # Or some other layers that you want. \n",
        "    if \"conv\" in param.name:\n",
        "        param.grad_req = 'null'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf2ZcO5knReu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1784e6c2-f8c4-4adc-9a51-a2c7dfe965a4"
      },
      "source": [
        "for param in net.collect_params().values():\n",
        "    print(param, param.grad_req)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter alexnet0_conv0_weight (shape=(64, 3, 11, 11), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv0_bias (shape=(64,), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv1_weight (shape=(192, 64, 5, 5), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv1_bias (shape=(192,), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv2_weight (shape=(384, 192, 3, 3), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv2_bias (shape=(384,), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv3_weight (shape=(256, 384, 3, 3), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv3_bias (shape=(256,), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv4_weight (shape=(256, 256, 3, 3), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_conv4_bias (shape=(256,), dtype=<class 'numpy.float32'>) null\n",
            "Parameter alexnet0_dense0_weight (shape=(4096, 9216), dtype=float32) write\n",
            "Parameter alexnet0_dense0_bias (shape=(4096,), dtype=float32) write\n",
            "Parameter alexnet0_dense1_weight (shape=(4096, 4096), dtype=float32) write\n",
            "Parameter alexnet0_dense1_bias (shape=(4096,), dtype=float32) write\n",
            "Parameter alexnet1_dense2_weight (shape=(5, 0), dtype=float32) write\n",
            "Parameter alexnet1_dense2_bias (shape=(5,), dtype=float32) write\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlUNIfM1nTVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}